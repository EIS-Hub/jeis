{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax \n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import optax\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\".5\"\n",
    "px = 1/plt.rcParams[\"figure.dpi\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,) (10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset, already flat and normalized\n",
    "X_train_1 = jnp.load('../mnist_np/X_train_1.npy') \n",
    "X_train_2 = jnp.load('../mnist_np/X_train_2.npy') \n",
    "X_train_3 = jnp.load('../mnist_np/X_train_3.npy') \n",
    "X_train_4 = jnp.load('../mnist_np/X_train_4.npy') \n",
    "# create X_train out of 4 X_trains\n",
    "X_train = jnp.concatenate([X_train_1, X_train_2, X_train_3, X_train_4], axis=0)\n",
    "y_train = jnp.load('../mnist_np/y_train.npy')\n",
    "X_test = jnp.load('../mnist_np/X_test.npy')\n",
    "y_test = jnp.load('../mnist_np/y_test.npy')\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding the data in batches of 2000 (going above take more time)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n"
     ]
    }
   ],
   "source": [
    "def rate_encoding(key, X, sim_len=100):\n",
    "    \n",
    "    def bernoulli_encoding(key, spike_trains, sim_len):\n",
    "        key, subkey = jax.random.split(key)\n",
    "        return key, jax.random.bernoulli(key, spike_trains, (sim_len, spike_trains.shape[0], spike_trains.shape[1]))\n",
    "    \n",
    "    print('Encoding the data in batches of 2000 (going above take more time)')\n",
    "    X_encoded = []\n",
    "    batch_size = 2000\n",
    "    for i in range(X.shape[0]//batch_size):\n",
    "        key, X_encoded_ = bernoulli_encoding(key, X[i*batch_size:(i+1)*batch_size], sim_len=100)\n",
    "        print(X_encoded_.shape)\n",
    "        X_encoded.append(X_encoded_)\n",
    "\n",
    "    return key, jnp.concatenate(X_encoded, axis=1)\n",
    "\n",
    "# do rate encoding on X_test\n",
    "key = jax.random.PRNGKey(9)\n",
    "key, X_test_encoded = rate_encoding(key, X_test, sim_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding the data in batches of 2000 (going above take more time)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n",
      "(100, 2000, 784)\n"
     ]
    }
   ],
   "source": [
    "# do rate encoding on Xtrain\n",
    "key, X_train_encoded = rate_encoding(key, X_train, sim_len=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.custom_jvp\n",
    "def gr_than(x, thr):\n",
    "    return (x > thr).astype(jnp.float32)\n",
    "\n",
    "@gr_than.defjvp\n",
    "def gr_jvp(primals, tangents):\n",
    "    x, thr = primals\n",
    "    x_dot, thr_dot = tangents\n",
    "    primal_out = gr_than(x, thr)\n",
    "    tangent_out = x_dot * 1 / (jnp.absolute(x-thr)+1)**2\n",
    "    return primal_out, tangent_out\n",
    "\n",
    "# TODO 1: extend the LIF model to have two layers\n",
    "# NOTE: nb of inputs and outputs are the same, the hidden layer dimension has to be defined\n",
    "# NOTE: a recurrent layer is defined at the hidden layer\n",
    "# NOTE: we want to return besides the state also the input current, V_mem of the hidden layer, V_mem and the output spikes of the output layer\n",
    "def lif_forward(state, input_spikes):\n",
    "    params, hidden_spikes, out_spikes2, I_in, V_mem1, V_mem2 = state[0]\n",
    "    tau_mem, Vth, timestep = state[1]\n",
    "    W01 = params[0]\n",
    "    W11 = params[1]\n",
    "    W12 = params[2]\n",
    "    \n",
    "    # Layer 1\n",
    "    I_in = jnp.dot(W01, input_spikes) # shape (8,1)\n",
    "    # recurrent connection\n",
    "    I_rec = jnp.dot(W11, hidden_spikes) # shape (8,1)\n",
    "    V_mem1 = (1 - timestep/tau_mem) * V_mem1 + I_rec + I_in - hidden_spikes * Vth\n",
    "    # constraining V_mem to be non-negative\n",
    "    V_mem1 = jnp.maximum(0, V_mem1)\n",
    "    hidden_spikes = gr_than(V_mem1, Vth)\n",
    "    # Layer 2\n",
    "    I_in2 = jnp.dot(W12, hidden_spikes)\n",
    "    V_mem2 = (1 - timestep/tau_mem) * V_mem2 + I_in2 # no reset, just integrate\n",
    "    # constraining V_mem to be non-negative\n",
    "    V_mem2 = jnp.maximum(0, V_mem2)\n",
    "    out_spikes2 = gr_than(V_mem2, Vth)\n",
    "    # return state\n",
    "    return ((params, hidden_spikes, out_spikes2, I_in, V_mem1, V_mem2), state[1]), (I_in, V_mem1, V_mem2, out_spikes2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomWeightInit(parent_key, scale, in_width, out_width):\n",
    "    in_width = in_width\n",
    "    out_width = out_width\n",
    "    weight_key, bias_key = jax.random.split(parent_key)\n",
    "    W = scale*jax.random.normal(weight_key, shape=(out_width, in_width))\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3: implement a multi-layer loss function\n",
    "def mini_loss(params, static_params, img, lbl):\n",
    "    # TODO 3.1: try to infer these values from your parameters\n",
    "    num_classes = params[2].shape[0]\n",
    "    num_hidden = params[1].shape[0]\n",
    "    \n",
    "    # TODO 3.2: initialize the multi-layer state variable\n",
    "    V_mem1 = jnp.zeros((num_hidden,), dtype='float32')\n",
    "    I_in = jnp.zeros((num_hidden,), dtype='float32')\n",
    "    hidden_spikes = jnp.zeros((num_hidden,), dtype='float32')\n",
    "    V_mem2 = jnp.zeros((num_classes,), dtype='float32')\n",
    "    out_spikes = jnp.zeros((num_classes,), dtype='float32')\n",
    "    state = ((params, hidden_spikes, out_spikes, I_in, V_mem1, V_mem2), static_params)\n",
    "\n",
    "    state, plot_values = jax.lax.scan(lif_forward,state,img)\n",
    "\n",
    "    # TODO 3.3: implement the loss calulcation accordingly\n",
    "    V_mem_data = plot_values[2]\n",
    "    max_per_class = V_mem_data.max(axis=0)\n",
    "    prediction = max_per_class.argmax()\n",
    "    logits = jax.nn.softmax(max_per_class)\n",
    "    loss = -jnp.mean(jnp.log(logits[lbl.astype(jnp.uint8)]))\n",
    "    acc = jnp.where(prediction == lbl, 1.0, 0.0)\n",
    "\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss fucntion\n",
    "def loss_fn_vmap(params, static_params, img_b, lbl_b):\n",
    "    batch_size = img_b.shape[0]\n",
    "    \n",
    "    local_loss = jnp.zeros(batch_size)\n",
    "    local_acc = jnp.zeros(batch_size)\n",
    "\n",
    "    local_loss, local_acc = jax.vmap(mini_loss, in_axes=(None, None, 0, 0))(params, static_params, img_b, lbl_b)\n",
    "    return local_loss.mean(), local_acc.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset():\n",
    "    def __init__(self, X_images,Y_labels):\n",
    "        self.imgs = X_images\n",
    "        self.lbls = Y_labels\n",
    "    def __len__(self): # return length of dataset, i.e. nb of MNIST pictures\n",
    "        return self.imgs.shape[1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.imgs[:,idx,:], self.lbls[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test functionality of MNISTDataset() class \n",
    "train_dataset = MNISTDataset(X_train_encoded, y_train)\n",
    "test_dataset = MNISTDataset(X_test_encoded, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size=128\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    transposed_data = list(zip(*batch))\n",
    "    labels= np.array(transposed_data[1])\n",
    "    imgs = np.stack(transposed_data[0])\n",
    "    return imgs, labels\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, collate_fn=custom_collate_fn, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False, collate_fn=custom_collate_fn, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training SNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "# TODO LATER: play around, try out different hidden layer dimensions and check out the resulting accuracy\n",
    "# NOTE: this one works sufficiently well\n",
    "num_hidden = 200\n",
    "\n",
    "# initialize state variables of LIF neuron for every time step\n",
    "\n",
    "# initialize dynamic params\n",
    "\n",
    "# TODO 2: modify/add parameters necessary for a multi-layer SNN\n",
    "\n",
    "seed = 9\n",
    "parent_key = jax.random.PRNGKey(seed)\n",
    "# TODO 2.1: initialize weights\n",
    "# NOTE: weights can be added to a list/tuple of weights (called params for instance), and passed as an argument\n",
    "# NOTE: weight scaling factor of 0.03 can be used\n",
    "# NOTE: refer to the JAX tutorial on weight updates with JAX using Pytrees to see why we are using it this way\n",
    "W01 = randomWeightInit(parent_key, 0.03, 784, num_hidden)\n",
    "W11 = randomWeightInit(parent_key, 0.03, num_hidden, num_hidden)\n",
    "W12 = randomWeightInit(parent_key, 0.03, num_hidden, num_classes)\n",
    "params = [W01, W11, W12]\n",
    "params_init = params\n",
    "\n",
    "tau_mem = 10e-3\n",
    "V_th = 1.0\n",
    "timestep = 1e-3\n",
    "\n",
    "static_params = (tau_mem, V_th, timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_updates: 468, n_updates_lr: 15, transition_steps: 31.0\n"
     ]
    }
   ],
   "source": [
    "# trying new optimizer with scheduler\n",
    "\n",
    "start_learning_rate = 1e-3\n",
    "n_epochs = 1\n",
    "hp = static_params\n",
    "\n",
    "n_batches = len(train_loader)\n",
    "n_updates = n_epochs * n_batches\n",
    "n_updates_lr = 15\n",
    "transition_steps = np.floor(n_updates / n_updates_lr)\n",
    "print(f'n_updates: {n_updates}, n_updates_lr: {n_updates_lr}, transition_steps: {transition_steps}')\n",
    "\n",
    "# Exponential decay of the learning rate.\n",
    "scheduler = optax.exponential_decay(\n",
    "    init_value=start_learning_rate,\n",
    "    transition_steps=transition_steps,\n",
    "    decay_rate=0.99)\n",
    "\n",
    "# Combining gradient transforms using `optax.chain`.\n",
    "gradient_transform = optax.chain(\n",
    "    optax.clip_by_global_norm(1.0),  # Clip by the gradient by the global norm.\n",
    "    optax.scale_by_adam(),  # Use the updates from adam.\n",
    "    optax.scale_by_schedule(scheduler),  # Use the learning rate from the scheduler.\n",
    "    # Scale updates by -1 since optax.apply_updates is additive and we want to descend on the loss.\n",
    "    optax.scale(-1.0)\n",
    ")\n",
    "\n",
    "opt_state = gradient_transform.init(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   batch_cnt  0 , b loss  2.028969 , b accuracy  0.359375\n",
      "   batch_cnt  25 , b loss  0.45821217 , b accuracy  0.875\n",
      "   batch_cnt  50 , b loss  0.43551442 , b accuracy  0.890625\n",
      "   batch_cnt  75 , b loss  0.27768892 , b accuracy  0.9140625\n",
      "   batch_cnt  100 , b loss  0.1510553 , b accuracy  0.9609375\n",
      "   batch_cnt  125 , b loss  0.18419889 , b accuracy  0.9375\n",
      "   batch_cnt  150 , b loss  0.15771265 , b accuracy  0.9375\n",
      "   batch_cnt  175 , b loss  0.15445891 , b accuracy  0.953125\n",
      "   batch_cnt  200 , b loss  0.122319125 , b accuracy  0.953125\n",
      "   batch_cnt  225 , b loss  0.21144049 , b accuracy  0.96875\n",
      "   batch_cnt  250 , b loss  0.16501155 , b accuracy  0.953125\n",
      "   batch_cnt  275 , b loss  0.24459182 , b accuracy  0.9375\n",
      "   batch_cnt  300 , b loss  0.11978734 , b accuracy  0.9453125\n",
      "   batch_cnt  325 , b loss  0.19209935 , b accuracy  0.9375\n",
      "   batch_cnt  350 , b loss  0.14458252 , b accuracy  0.9765625\n",
      "   batch_cnt  375 , b loss  0.10305858 , b accuracy  0.9609375\n",
      "   batch_cnt  400 , b loss  0.13508034 , b accuracy  0.9453125\n",
      "   batch_cnt  425 , b loss  0.18369311 , b accuracy  0.9375\n",
      "   batch_cnt  450 , b loss  0.09796811 , b accuracy  0.96875\n",
      "\n",
      "epoch  0 , e loss  0.22185814 , e acc 0.9329928\n",
      "\n",
      "params saved\n",
      "\n",
      "   batch_cnt  0 , b loss  0.11349971 , b accuracy  0.96875\n",
      "   batch_cnt  25 , b loss  0.037931174 , b accuracy  0.9921875\n",
      "   batch_cnt  50 , b loss  0.033816684 , b accuracy  0.984375\n",
      "   batch_cnt  75 , b loss  0.03727047 , b accuracy  0.9921875\n",
      "   batch_cnt  100 , b loss  0.0892631 , b accuracy  0.984375\n",
      "   batch_cnt  125 , b loss  0.122544274 , b accuracy  0.9609375\n",
      "   batch_cnt  150 , b loss  0.12422677 , b accuracy  0.9453125\n",
      "   batch_cnt  175 , b loss  0.08366426 , b accuracy  0.96875\n",
      "   batch_cnt  200 , b loss  0.04472046 , b accuracy  0.9921875\n",
      "   batch_cnt  225 , b loss  0.057147197 , b accuracy  0.984375\n",
      "   batch_cnt  250 , b loss  0.058981016 , b accuracy  0.984375\n",
      "   batch_cnt  275 , b loss  0.12384177 , b accuracy  0.953125\n",
      "   batch_cnt  300 , b loss  0.08423829 , b accuracy  0.9921875\n",
      "   batch_cnt  325 , b loss  0.08365791 , b accuracy  0.984375\n",
      "   batch_cnt  350 , b loss  0.09462012 , b accuracy  0.953125\n",
      "   batch_cnt  375 , b loss  0.045230538 , b accuracy  0.9765625\n",
      "   batch_cnt  400 , b loss  0.077970475 , b accuracy  0.96875\n",
      "   batch_cnt  425 , b loss  0.015901288 , b accuracy  1.0\n",
      "   batch_cnt  450 , b loss  0.0719786 , b accuracy  0.96875\n",
      "\n",
      "epoch  1 , e loss  0.08136773 , e acc 0.97472626\n",
      "\n",
      "params saved\n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "best_acc = 0.5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = jnp.zeros(len(train_loader))\n",
    "    epoch_acc = jnp.zeros(len(train_loader))\n",
    "    # continue training for one whole epoch using mini loss\n",
    "    for batch_cnt, (img_batch, lbl_batch) in enumerate(train_loader):\n",
    "      (batch_loss, batch_acc), weight_grad = jax.value_and_grad(loss_fn_vmap, has_aux=True)(params, static_params, img_batch, lbl_batch)\n",
    "      updates, opt_state = gradient_transform.update(weight_grad, opt_state)\n",
    "      params = optax.apply_updates(params, updates)\n",
    "\n",
    "      # logging\n",
    "      if batch_cnt % 25 == 0:\n",
    "          print('   batch_cnt ', batch_cnt, ', b loss ', batch_loss, ', b accuracy ', batch_acc)\n",
    "\n",
    "      epoch_loss = epoch_loss.at[batch_cnt].set(batch_loss)\n",
    "      epoch_acc = epoch_acc.at[batch_cnt].set(batch_acc)\n",
    "\n",
    "    epoch_loss = epoch_loss.mean()\n",
    "    epoch_acc = epoch_acc.mean()\n",
    "\n",
    "    print('')\n",
    "    print('epoch ', epoch, ', e loss ', epoch_loss, ', e acc', epoch_acc)\n",
    "    print('')\n",
    "\n",
    "    # save best performing weight (per epoch)\n",
    "    if batch_acc > best_acc:\n",
    "      # TODO 2.3: save the best performing weights into params_final\n",
    "      params_final = params\n",
    "      best_acc = epoch_acc\n",
    "      print('params saved')\n",
    "      print('')\n",
    "\n",
    "\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing SNN on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   batch_cnt  0 , b loss  0.014911274 , b accuracy  1.0\n",
      "   batch_cnt  25 , b loss  0.018335955 , b accuracy  1.0\n",
      "   batch_cnt  50 , b loss  0.010366419 , b accuracy  1.0\n",
      "   batch_cnt  75 , b loss  0.06859748 , b accuracy  0.984375\n",
      "\n",
      "epoch  0 , e loss  0.0798819 , e acc 0.97465944\n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "batch_img, batch_lbl = next(iter(test_loader))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = jnp.zeros(len(test_loader))\n",
    "    epoch_acc = jnp.zeros(len(test_loader))\n",
    "    # continue training for one whole epoch using mini loss\n",
    "    for batch_cnt, (img_batch, lbl_batch) in enumerate(test_loader):\n",
    "\n",
    "      # simple inference using W_final\n",
    "      batch_loss, batch_acc = loss_fn_vmap(params_final, static_params, img_batch, lbl_batch)\n",
    "\n",
    "      # logging\n",
    "      if batch_cnt % 25 == 0:\n",
    "          print('   batch_cnt ', batch_cnt, ', b loss ', batch_loss, ', b accuracy ', batch_acc)\n",
    "\n",
    "      epoch_loss = epoch_loss.at[batch_cnt].set(batch_loss)\n",
    "      epoch_acc = epoch_acc.at[batch_cnt].set(batch_acc)\n",
    "\n",
    "    epoch_loss = epoch_loss.mean()\n",
    "    epoch_acc = epoch_acc.mean()\n",
    "\n",
    "    print('')\n",
    "    print('epoch ', epoch, ', e loss ', epoch_loss, ', e acc', epoch_acc)\n",
    "    print('')\n",
    "\n",
    "\n",
    "print('DONE')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
